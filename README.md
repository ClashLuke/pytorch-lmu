# PyTorch LMU
This repository contains a PyTorch implementation of Legendre Memory Units (LMUs), as presented in the [NeurIPS 2019 paper](https://papers.nips.cc/paper/9689-legendre-memory-units-continuous-time-representation-in-recurrent-neural-networks) by Voelker AR, Kajić I and Eliasmith C.  
SOTA performance on the psMNIST dataset is reproduced in [`examples/`](examples).

## References
- [Voelker, Aaron R., Ivana Kajić, and Chris Eliasmith. "Legendre memory units: Continuous-time representation in recurrent neural networks." (2019).](https://papers.nips.cc/paper/9689-legendre-memory-units-continuous-time-representation-in-recurrent-neural-networks)
- [Legendre Memory Units in NengoDL](https://www.nengo.ai/nengo-dl/examples/lmu.html)
- [nengo/keras-lmu](https://github.com/nengo/keras-lmu)
